各位口試委員好，我叫凃建名
我今天要報告的題目是以卷積神經網路為基礎之新型可解釋性深度學習模型
A New CNN-Based Interpretable Deep Learning Model

在開始前，
我想要先跟各位口試委員報告，
在初稿寄出我有對論文的進行以上的更正，
首先是將原本論文中的3.4和3.3章節互換使得閱讀上更容易理解
其次我有原3.4章節的過濾公式變更成以上的公式並重新說明了這個公式，
最後是將原3.4章節的Triangle cReLU公式移動至4.4.5章節，
這些變更都已更新在各位委員桌上的紙本論文和等等的說明中。

那我便開始進行說明，
我的報告大綱共有五個部分，分別是
緒論、背景知識與文獻回顧、研究方法、實驗設計與成果、結果與未來展望。

首先是研究動機與目的，
隨著深度學習的蓬勃發展，人工智慧的應用也漸漸普及到各行各業，
然而現在大部分SOTA模型卻均為所謂黑盒模型，
也就是我們雖然了解模型的運行原理，
但卻無法說明其作出每一個決策的根據或理由。
而在特定的關鍵領域中，例如金融和醫療，
卻往往需要有足以支撐預測結果的理由和背後的邏輯，
其結論才足以被使用者所接受。

在2016年美國國防部將可解釋性人工智慧加入國防高等研究署的計畫，
和同年歐盟通過的《一般資料保護原則》中裡面規範使用者有獲得關於推論資訊的權利，
以上兩件事我們可以知道可解釋性人工智慧不僅僅在學術和企業界甚至在國家層面上都受到重視。