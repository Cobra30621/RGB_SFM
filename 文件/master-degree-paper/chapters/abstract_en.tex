\documentclass[class=NCU_thesis, crop=false]{standalone}
\begin{document}

\chapter{Abstract}

As deep learning technology is widely applied across various fields, the importance of interpretable models has become increasingly prominent. Many high-performance deep learning models, despite their excellent predictive accuracy, exhibit a "black-box" nature that makes it difficult for users to understand their internal workings and decision-making processes. In fields requiring high reliability and transparency, such as healthcare, finance, and military applications, the interpretability of models is crucial. Models capable of explaining their decision processes not only enhance user trust but also provide valuable insights in case of anomalies.

This study proposes a new CNN-based interpretable deep learning model, aimed at improving the transparency and interpretability of the model. The model comprises three major components: a color perception block, an edge detection block, and a feature transmission block. The color perception block extracts color features from the input image by calculating the similarity between the average colors of different parts of the input image and 30 basic hues. The edge detection block converts the colored image into a grayscale image through preprocessing and detects edge features by calculating the similarity between different parts of the input image and filters.The color feature transmission block and the edge feature transmission block simulate the multi-layer structure of the visual cortex. After the features are input to each layer, they learn features through Gaussian convolution and feature enhancement modules. The image features are then combined in a sequential manner to form more comprehensive feature outputs to the next layer, repeating this process. Finally, the color features and edge features are combined and input into the fully connected layer for classification. Through these designs, the model maintains high accuracy while providing clear and understandable decision processes.

The study used three datasets: MNIST, Colored MNIST, and Colored Fashion MNIST. The experimental results from these datasets indicate that the proposed model performs well in terms of both interpretability and performance. Especially on the Colored MNIST and Colored Fashion MNIST datasets, the model can accurately distinguish images of different colors and shapes and visualize the internal decision logic of the model, thereby verifying its interpretability and practicality. These results confirm the potential and effectiveness of the model in enhancing the interpretability of deep learning models.

\vspace{2em}
\noindent \textbf{Keywords:} \keywordsEn{} % Set keywords in config.tex
\end{document}