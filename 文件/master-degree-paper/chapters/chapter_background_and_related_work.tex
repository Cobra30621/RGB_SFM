\documentclass[class=NCU_thesis, crop=false]{standalone}
\begin{document}

\chapter{背景知識以及文獻回顧}
\section{背景知識}
\subsection{卷積神經網路}




\subsection{人如何感知彩色影像}


\section{文獻回顧}

\subsection{可解釋性人工智慧的演進與分類}
Decision Tree:
\cite{rokach2016decision}
\cite{grinsztajn2022treebased}

介紹可解釋性人工智慧的歷程，分類，各分類著名的論文的簡介

\subsection{對於 Inherently Interpretable 可解釋性模型之研究}
\subsubsection{基於多層自我映射圖之可視覺化深度學習模型}

\subsection{對於 Post-hoc 可解釋性模型之研究}
\subsubsection{Local Interpretable Model-agnostic Explanations(LIME)} 
\subsubsection{Shapley Additive Explanations(SHAP)}

\subsection{近年可解釋性模型趨勢之研究}
\subsubsection{Tabnet: Attentive interpretable tabular learning}
\subsubsection{Building more explainable artificial intelligence with argumentation}
XAI的新趨勢使用論證的方式來解釋，特別是計算論證有助於理解理性決策的所有步驟以及在不確定性下進行推理。 \cite{LONGO2024102301}

\subsection{以卷積神經網路為基礎的具可解釋性的深度學習模型}

\end{document}