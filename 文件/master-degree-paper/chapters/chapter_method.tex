\documentclass[class=NCU_thesis, crop=false]{standalone}
\begin{document}

\chapter{研究方法}

\section{以卷積神經網路為基礎的RGB彩色可解釋性模型}
\subsection{模型架構}

此章節將介紹本論文所提出的可解釋性模型整體架構與每個部分的功能，並說明資料在模型中的運作方式，模型架構圖如\cref{fig:model_arch}。
整個模型可以分成三個部分，色彩感知區塊、輪廓感知區塊和特徵傳遞區塊。

\fig[1][fig:model_arch][H]{model_arch.png}[模型架構圖][模型架構圖]


色彩感知區塊基於 Thomas Young 所提出的三色視覺理論(Trichromacy Theory)\cite{}，
透過模擬眼球中的三種類型的視錐細胞，
提取與學習影像中不同區塊的RGB的比例，以提取影像中每個區塊的色彩特徵。
輪廓感知區塊透過將影像進行灰階化後使用高斯卷積層來提取影像中輪廓和邊緣的特徵。
特徵感知區塊使用了 CIM 模型模擬了大腦皮質的運作模式並對其進行優化，
每一層的 Block 都會將底層的特徵資訊整合並傳遞到下一層進行學習。 
特徵傳遞層的 Block 可以分成三個部分，
高斯卷積模組，特徵增強模組，空間合併模組，
高斯卷積模組負責學習與提取輸入的特徵，
特徵增強模組負責過濾不重要的特徵，空間合併模組則模擬皮層的資訊合併，融合眼球跳動的概念，將輸入的資訊根據空間位置關係進行合併。


\subsection{演算法流程}
Step 1：決定整個模型的架構與參數

Step 2：對輸入的彩色影像做灰階化產生對應的灰階影像

Step 3：將彩色影像和灰階影像分別輸入色彩提取層和輪廓提取層提取出色彩特徵與輪廓特徵

Step 4：在獲得色彩特徵與輪廓特徵時將他們合併在一起形成一個綜合特徵

Step 5：將綜合特徵輸入特徵傳遞層進行綜合特徵的學習與合併

Step 6：將完整的特徵資訊輸入全連接層學習分類特徵

Step 7：將色彩提取區塊的 weight 正規化至 [0,1] 之間

Step 8：計算 loss value 並進行反向傳播

\pagebreak

\subsection{模型符號說明}
	由於本研究在可解釋性部分採用了CIM中的特徵圖解析方法來解析本論文模型的決策過程，
	因此在各個區塊我們均會產生特徵映射圖(Feature Map, FM)、特徵映射響應圖(Response Image, RM)和特徵映射圖之對應影像(Corresponding Image, CI)作為可解釋性的核心要素。
	具體的產生過程將會在\cref{section:InterablePicture}去介紹。

	\begin{description}
		\item[]\textit{FM}$_{color}$：色彩感知區塊之高斯卷積模組的\textit{FM}
		\item[]\textit{RM}$_{color}$：色彩感知區塊之高斯卷積模組的\textit{RM}
		
		\item[]\textit{FM}$_{gray}$：輪廓感知區塊之高斯卷積模組的\textit{FM}
		\item[]\textit{RM}$_{gray}$：輪廓感知區塊之高斯卷積模組的\textit{RM}
		\item[]\textit{CI}$_{gray}$：輪廓感知區塊之高斯卷機模組的\textit{FM}$_{gray}$的對應影像

		\item[]\textit{FM}$_{i}$：特徵傳遞區塊第i層之高斯卷積模組的\textit{FM}
		\item[]\textit{RM}$_{i}$：特徵傳遞區塊第i層之高斯卷積模組的\textit{RM}
		\item[]\textit{CI}$_{i}$：特徵傳遞區塊第i層之高斯卷積模組的\textit{FM}$_{i}$的對應影像
	\end{description}

\pagebreak

\section{色彩提取區塊設計與實現}

此章節將說明本論文所提出的色彩提取區塊設計與實現，
該區塊主要是透過將濾波器(Filter)的初始化為不同的RGB色彩值來作為該區塊的權重，
並使用高斯卷積模組計算出影像中不同區塊之色彩與filter的相似度，
後將結果送入特徵增強模組，最終形成影像的色彩特徵。
這樣的方法目的在於模擬人眼中的三類視錐細胞基於RGB值來感知不同外界的色彩的過程，
並透過卷積操作來去模擬人眼的眼球跳動，
從而重現人眼獲得色彩特徵的完整流程。
以下將針對 Filter 初始化、彩色卷積模組、訓練過程中的正規化三個部分進行詳細說明。

	\subsection{Filter初始化}

	由於色彩提取區塊的輸入為彩色影像其輸入通道分別為紅、綠、 藍三色的通道，
	我們令輸出的通道數為 \textit{C}$_{out}$ 、 kernel 的長、寬為 \textit{H}$_{kernel}$ 、 \textit{W}$_{kernel}$，
	因此， Filter 的形狀為 $\left(C_{out} , 3, H_{kernel}, W_{kernel}\right)$。
	我們將 Filter 視為 \textit{C}$_{out}$ 個不同RGB色彩的 \textit{H}$_{kernel}$ * \textit{W}$_{kernel}$ 的色塊，
	這樣設置的目的是希望可以讓色彩提取區塊專注於學習影像中不同區域的色彩分布和色彩特徵，而不需要額外去學習輪廓特徵。

	在實作中，我們先使用 Kaiming Uniform 的方式將RGB三個通道分別初始化出\textit{C}$_{out}$個，
	根據 kaiming 論文\cite{DBLP:journals/corr/HeZR015}中的方式將每個值初始化範圍為$[-\sqrt{\frac{6}{\text{fan\_in}}}, \sqrt{\frac{6}{\text{fan\_in}}}]$,
	$\text{fan\_in}$ 為輸入通道數。
	此處的目的是希望初始化出 \textit{C}$_{out}$ 種不同的RGB色彩,形成 $\left(C_{out} , 3\right)$ 的值，
	並且再將這 \textit{C}$_{out}$ 的色彩重複擴張成 \textit{H}$_{kernel}$ * \textit{W}$_{kernel}$ 的色塊。

	我們在實作中選擇使用 Kaiming Uniform 的原因是因為 Kaiming Uniformm 相較於常用的 Uniform 初始化和 Xavier Uniform\cite{pmlr-v9-glorot10a} 初始化多考慮了整流線性單位函數(ReLU)的存在，
	Uniform 初始化的方式無法解決隨著神經網路的增加而導致梯度消失的問題，
	Xavier Uniform 為了解決梯度消失問題加入了 rescale 函數 $\frac{1} / \sqrt{\text{n}}$但卻只適用於激活函數為線性函數的情況下，
	而 Kaiming Uniform 在解決梯度消失的問題時同時考慮了激活函數為非線性函數的情況並在\cite{DBLP:journals/corr/HeZR015}透過實驗證明了kaiming uniform 在神經網路在不影響準確度的同時更快收斂。
	由於我們的模型中在特徵增強模組中使用的非線性函數ReLU的變形去進行特徵增強，因此選擇了 Kaiming Uniform 來去進行後面的實驗。

	\subsection{彩色卷積模組}

	\subsection{訓練過程的正規化}

\section{輪廓感知區塊之設計}
輪廓感知區塊應用了CIM模型中提取特徵的方式，
先是使用高斯卷積模組去計算輸入的灰階影像與濾波器之間的相似度作為輪廓的特徵，
並使用特徵增強模組過濾不重要的特徵、突顯重要特徵(與濾波器相似度高的影像部分)。

\colorbox {yellow}{放點架構和灰階輪廓圖片}

\section{色彩與輪廓特徵的結合}
\colorbox {yellow}{目前是concat}

\section{特徵傳遞區塊之優化設計}
特徵傳遞區塊以 CIM 為基礎，對 CIM 的原始區塊進行深入分析和改進並對其進行優化，
我們希望可以這些優化措施可以在可解釋性不變的同時，又可以對模型的效能和準確度進行提升，
此外我們還希望這些優化措施可以將一些原本人工去分析資料集後指定的參數變成可訓練參數，
進一步提高模型的自動化與適應能力。

	\subsection{高斯卷積模組優化設計}

	\colorbox {yellow}{補CNN的cite}
	在高斯卷積模組中，
	CIM的原始實作方法修改了傳統CNN\cite{}中的卷積操作，
	將CNN卷積操作的內積轉換為放射狀積底函數的高斯函數，
	目的是希望以距離為基礎的高斯函數可以表達輸入與Filter之間的距離關係並將之視為相似度。

	在實作上CIM採用了逐個計算每個 Windows 和濾波器之間的歐式距離並將結果輸入進高斯函數得出相似度。
	我們改進了這個實作過程，利用了 GPU 的多核優勢，
	將每次卷積的所有位置的 Windows 取出來後平行放入 GPU 的多個核心，
	同時計算這些 Windows 與濾波器的歐式距離再輸入高斯函數中得出相似度，
	這樣的實作方式使得整體模型的訓練速度可以大幅提高，
	也完整利用GPU的效能，提升了模型效率。

	\colorbox {yellow}{可以加入原本的卷積方式和平行處理的方式的示意圖}

	\subsection{特徵增強模組之優化設計}
	在特徵增強模組中，
	CIM 使用了自行設計的增強特徵的整流線性單位函數(changed ReLU, 簡稱cReLU)，
	希望透過閥值過濾不重要的特徵，其公式如\cref{eq:eq-crelu}所示。
	作為閥值的 $c$ 值需要透過觀察資料集在高斯卷積模組的輸出來設定具體不同的$c$的數值來適應不同的資料集。
	然而一旦閥值設定過小則會削弱特徵增強的效果，
	閥值設定過大則會將大部分的特徵都歸零導致無法學習出有效特徵，
	因此如何設定 $c$ 則成為一個非常困難的問題，並且每次更換資料集都必須面對這個問題。

	為了解決閥值設定的問題，
	我們設計了一套確定 $c$ 數值的方法，
	首先設定一個希望保留的$RM$元素的百分比參數 $p\%$，
	接著從同一影像在該層的所有 $RM$ 中取出第 $p\% * RM的數目$  個最大的元素，
	作為$c$的數值，並且將所有小於$c$的數值歸零。
	如此一來，使用者只需要決定希望可以保留 $p\%$ 的數值，
	無須糾結於設定閥值$c$具體數值。
	這種方法簡化了參數設定過程，
	同時也確保了特徵增強的有效性。


	\subsection{空間位置保留機制之優化設計}
	在空間保留機制模組上，
	CIM為了保留 $RM$ 之間的空間位置關係簡化了眼球跳動的方式，
	加入了一個可訓練的時間遺忘函數 $\alpha$ 進入合併公式\cref{eq:eq-sf}。
	CIM之合併公式:\\
		$RM_{c}$為合併後的RM，$RM_{k}$為第k張RM，$n$為輸入資訊的數量，$\alpha$為一個可訓練的參數
		\begin{equation}
		    \label{eq:eq-sf}
		    RM_{c}=\frac{1}{n} \sum_{k = 0}^{n-1} \alpha^{k} \times RM_{k}  \qquad ,\ where\ n = \textit{H}^{i}_{SF} \times \textit{W}^{i}_{SF}
		\end{equation}
	這樣會導致越早被看到(時間越早)的數值需要乘上的 $\alpha^{k}$ 的 $k$ 值越大，
	在合併時的加權也就越小。
	儘管這種做法確實可以使$RM$呈現出空間上的關係，
	然而當我們需要合併的$RM_{k}$越多時，
	隨著$k$ 值越來越大，$\alpha^{k}$會快速變小。
	這樣便造成當我們將$RM_{k}$ 乘上過小的的$\alpha^{k}$後，
	便會變得這個數值便會在$RM_{c}$中變得無足輕重。
	
	\colorbox {yellow}{可以放入$\alpha$的指數變化圖}

	對於大小較大的影像而言這種方法是有問題的，
	這會使得影像逐漸喪失一部分$ RM_{k} $ 所擷取的特徵。
	因此我們提出了將 $\alpha$ 的方法從$\alpha^{k}$，
	改成從[ $0.9 \sim 0.99$ ]之間進行等距採樣，
	得到 $k$ 個值代替 $\alpha^{k}$ 按照時序順序去乘以 $RM_{k}$ ，
	我們將第 $k$ 個RM所對應的 $\alpha$ 稱為 $\beta_{k}$，
	如此便可以改善當需要合併的 $RM$ 數量過多時 $\alpha^{k}$ 過小的問題，
	同時也保留了CIM當初設計時希望保留的 $RM$ 之間的對應空間關係。\\
	改善後的合併公式如\cref{eq:eq-sf-update}，$\beta_{k}$從[$0.9 \sim 0.99$]之間取出的第$k$個值:\\
		\begin{equation}
		    \label{eq:eq-sf-update}
		    RM_{c}=\frac{1}{n} \sum_{k = 0}^{n-1} \beta_{k} \times RM_{k}  \qquad ,\ where\ n = \textit{H}^{i}_{SF} \times \textit{W}^{i}_{SF}
		\end{equation}
	\colorbox {yellow}{可以放等距取值示意圖\cite{YangCNNInterpretable}}

	\subsection{模型流程的精簡}

	我們將原來在CIM的模型訓練流程中每層接在空間位置保留合併模組後的維度轉置與Reshape步驟(在\cite{YangCNNInterpretable}模型流程的 Step 4)去除，
	CIM會加入這個步驟的初衷在於方便之後輸出將濾波器輸出成可解釋性圖片，
	然而加入這個步驟導致一些不必要的問題：
	首先，CIM原本在第一層高斯卷積後的高斯卷積模組都只是做(1,1)的卷積操作，但是加入了這個步驟就會將後續的高斯卷積層的濾波器大小改變，容易引起閱讀者的誤解。
	其次，這個步驟並不會增加準確度或是增加效能，反而是多一些所轉置與Reshape所需要的時間。
	基於以上原因我們決定將此步驟捨棄，使過程容易理解、減少所需時間。

	\colorbox {yellow}{加入我們刪除了原先模型流程中的哪個步驟}



\section{可解釋性} 
本研究使用了Yang 在2023年CIM論文中提出的特徵映射法做為解析模型的決策過程的基礎，
使得模型的決策過程可以被視覺化出來，
讓使用者了解模型關注的特徵資訊與決策背後的邏輯關係。
	
	\subsection{FM、RM、CI的意義}
	\label{section:InterablePicture}
	特徵映射圖(FM)、特徵映射響應圖(RM)、特徵映射圖之對應影像(CI)，
	為Yang在CIM論文中提出的名詞，
	也是特徵映射法的核心三要素。

	特徵映射響應圖(RM)為當輸入進入高斯卷積模組後所得到的輸出，
	其代表的是輸入對於該高斯卷積模組的濾波器的相似度，
	也被視為輸入對該高斯卷機模組所有的濾波器的反應強度。
	同一層、不同位置的RM數值為輸入影像的不同位置對於某個濾波器的反應，
	不同層、同一位置的RM數值為輸入影像的同一位置對於不同濾波器的反應。

	特徵映射圖(FM)為將高斯卷積模組的濾波器提取出來並Reshape成二維矩陣所形成，
	由於模型在高斯卷積模組為計算輸入濾波器與相似度，
	因此FM可以被視為模型學習到了輸入影像中的何種特徵。

	特徵映射圖之對應影像(CI)為記錄資料集中所有影像對特定濾波器的反應，
	從中選出與該濾波器有最大的反應的影像，
	並該輸入影像視為該濾波器的對應影像。
	會需要CI的原因在於除了顏色感知層和輪廓感知層之外，
	後續的特徵傳遞層的輸入均為前一層所計算出來的相似度，
	人類已無法去解讀出FM的意義。
	因此我們需要透過CI來找出該濾波器與何種影像最相似，
	幫助使用者理解FM代表的特徵長相。

	\subsection{色彩感知區塊之可解釋性}
	我們第一步先找出色彩感知區塊中輸入影像的RM，
	第二步從RM中所有反應強度中找到最大的反應數值，
	第三步最大的RM數值中找出造成最大反應的FM，

	由於本研究之模型在色彩感知區塊的 FM 本身
	即可被視為 \textit{C}$_{out}$ 個不同RGB顏色，
	並且FM的這個特性導致FM不會學習到輪廓的特徵，
	CI對應出來的影像反而卻同時存在顏色和輪廓，
	這會導致最後組合起來導致CI容易出現顏色相似但輪廓完全不同的情況，
	反而沒有FM來的容易理解。

	\subsection{輪廓感知區塊和特徵學習區塊之可解釋性}
	
	

\section{量化推論成果之方法}


\end{document}