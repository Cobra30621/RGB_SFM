\documentclass[class=NCU_thesis, crop=false]{standalone}
\begin{document}

\chapter{緒論}
\section{研究動機}

自1998年LeNet\cite{726791}問世以來，隨著深度學習的蓬勃發展，人工智慧應用範圍也逐步融入到人們日常生活的方方面面。
然而儘管人工智慧的發展如此蓬勃，實際上我們對於人工智慧的實際運作過程與做出決策的理由仍然存在著許多未知的地方，
目前，大部分模型彷彿是一個黑盒子，我們雖了解其運作理論，但卻無法得知其每個決策的具體理由和依據。

當人工智慧開始運用到各行各業時，人們開始發覺在某些領域或是應用情境(如：醫療決策、軍事領域、金融決策等)下，
單單只有高準確度是無法讓使用者具備足夠的信心採用人工智慧所預測的決策，
這些領域所需要的決策往往需要合理的理由或是因果關係的推論支撐才足以讓使用者有足夠的信心採用，
在此情況下，具備可解釋性的深度學習模型做出令使用者有信心採用的決策。

隨著美國國防部MAPPA在2016年將可解釋性人工智慧（XAI）列為third-wave AI systems列為DARPA計畫項目之一\cite{DARPA}、
歐盟也在同年通過了《 European Union's General Data Protection Regulation (GDPR) 》裡面規範使用者有獲得有關於推論資訊的 "meaningful information about the logic involved" 的權利\cite{GDPR2016a},\cite{doi:10.1080/13600834.2019.1573501}。 這些重要的政策舉措使得可解釋性的深度學習模型成為了全球範圍內的熱門研究，不僅在學術界，也在企業界甚至國家層面都被視為重要的發展項目。

\pagebreak
\section{研究目的}
本論文旨在深入研究2023年由J.-F. Yang 等人所提出之 CNN-based Interpretable Model(以下簡稱CIM) \cite{YangCNNInterpretable}，
在此基礎上進行效能改進並進一步開發出一個不只適用於灰階影像而能更廣泛的適用於RGB彩色影像之可解釋性模型，
使其在保持原來CIM模型的高準確度與高可解釋性的水準下可以應用於更多現實影像分類任務。

透過研究人眼如何辨識彩色影像，
我們希望設計出用於模擬人眼感知色彩機構的色彩感知層和感知輪廓的輪廓感知層，
使模型可以模仿人眼感知色彩的過程，並將兩者資訊結合後輸入CIM。
藉由CIM模型的階層式時序處理，模擬人腦多層皮質資訊傳遞，
每一層都將擁有色彩和輪廓的特徵資訊，最終形成一個完整的影像特徵資訊，
並輸入全連接層以學習每個分類的特徵。

此外本論文也希望開發出來的適用於RGB彩色可解釋性模型能夠針對每一層的輸出之特徵進行分析，
並找出各層輸出特徵與最後預測分類之間的關係，以理解該模型是根據何種特徵做出分類判斷，從而形成一個使用者可以接受之解釋。


\pagebreak
\section{論文架構}

本論文分為五個章節，架構如下:

第一章：緒論，敘述本論文的研究動機、目的和架構

第二章：背景知識與文件回顧，介紹本論文所需之背景知識與回顧可解釋性人工智慧的演進與各個分類的重要論文

第三章：研究方法，介紹本論文對 以卷積神經網路為基礎的RGB彩色可解釋性模型的架構與方法

第四章：實驗設計與結果，對本論文所提出的方法在不同資料集上的效果進行實驗與觀察

第五章：總結，對本論文之結果做出結論並提出未來可行之研究方向


\end{document}

