{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Grayscale\n",
    "from load_data import CustomMNISTDataset, get_MalariaCellImagesDataset\n",
    "from utils import plot_map, test, get_ci, infer_data, get_ci\n",
    "from tqdm import tqdm\n",
    "from models import SOMNetwork\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "root = os.getcwd()\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CustomMNISTDataset(\n",
    "    root=f'{root}/data/MNIST',\n",
    "    train=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "testing_data = CustomMNISTDataset(\n",
    "    root=f'{root}/data/MNIST',\n",
    "    train=False,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_aug_data = CustomMNISTDataset(\n",
    "    root=f'{root}/data/MNIST',\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    augmentation=True\n",
    ")\n",
    "\n",
    "# training_data = datasets.FashionMNIST(\n",
    "#     root=f\"{root}/data\",\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=ToTensor()\n",
    "# )\n",
    "\n",
    "# testing_data = datasets.FashionMNIST(\n",
    "#     root=f\"{root}/data\",\n",
    "#     train=False,\n",
    "#     download=True,\n",
    "#     transform=ToTensor()\n",
    "# )\n",
    "batch_size = 60000\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=batch_size, shuffle=True)\n",
    "train_dataloader, valid_dataloader, test_dataloader = get_MalariaCellImagesDataset(root=f\"{root}/data/cell_images/\", resize=[28, 28], valid_size=0.0, test_size = 0.2, batch_size=batch_size, shuffle=True)\n",
    "# test_aug_dataloader = DataLoader(test_aug_data, batch_size=batch_size, shuffle=True)\n",
    "X, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "stride = 4\n",
    "in_channels = X.shape[1]\n",
    "out_channels = 2\n",
    "\n",
    "# filters = [(1, 6), (3, 1), (2, 1), (1, 1)]\n",
    "# kernels = [(10, 10), (15, 15), (25, 25), (35, 35)]\n",
    "# model_dict = torch.load(f'{root}/result_pth/our_300_97.19_mnist_4layer_3stride_18412111_0702.pth', map_location=device)\n",
    "\n",
    "filters = [(2, 2), (1, 3), (3, 1), (1, 1)]\n",
    "kernels = [(15, 15), (25, 25), (30, 30), (45, 45)]\n",
    "model_dict = torch.load(f'{root}/result_pth/our_2000_85.44728724369442_malaria_4layer_4stride_22133111_15253045.pth', map_location=device)\n",
    "\n",
    "model = SOMNetwork(stride=stride, in_channels=in_channels, out_channels=out_channels, kernels=kernels, filters=filters).to(device)\n",
    "model.load_state_dict(model_dict)\n",
    "print(\"Train: \\n\\tAccuracy: {}, Avg loss: {} \\n\".format(*test(train_dataloader, model, loss_fn, device=device))) \n",
    "print(\"Test: \\n\\tAccuracy: {}, Avg loss: {} \\n\".format(*test(test_dataloader, model, loss_fn, device=device))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FMs = {}\n",
    "if model.in_channels == 1:\n",
    "    FMs[1] = model.layer1[0].weight\n",
    "elif model.in_channels == 3:\n",
    "    FMs[1] = {\n",
    "        'gray': model.layer1[0].gray_weight,\n",
    "        'rgb': torch.repeat_interleave(torch.repeat_interleave(model.layer1[0].rgb_weight.reshape(model.layer1[0].rgb_weight.shape[0], model.layer1[0].rgb_weight.shape[1], 1, 1), model.layer1[0].kernel_size[0], dim=2), model.layer1[0].kernel_size[1], dim=3)\n",
    "    }\n",
    "FMs[2] = model.layer2[0].weight\n",
    "FMs[3] = model.layer3[0].weight\n",
    "FMs[4] = model.layer4[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMs = {}\n",
    "RMs[1] = model.layer1[0:-1](X).permute(0, 2, 3, 1).reshape(X.shape[0],-1, model.layer1[0].out_channels)\n",
    "RMs[2] = torch.nn.Sequential(*(list(model.layer1)+list(model.layer2)))[0:-1](X).squeeze().reshape(X.shape[0], -1, model.layer2[0].out_channels)\n",
    "RMs[3] = torch.nn.Sequential(*(list(model.layer1)+list(model.layer2)+list(model.layer3)))[0:-1](X).squeeze().reshape(X.shape[0], -1, model.layer3[0].out_channels)\n",
    "RMs[4] = torch.nn.Sequential(*(list(model.layer1)+list(model.layer2)+list(model.layer3)+list(model.layer4)))(X).squeeze().reshape(X.shape[0], -1, model.layer4[0].out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIs = {}\n",
    "CIs[1] = get_ci(X, layer=torch.nn.Sequential(*(list(model.layer1)))[0], n_filters=model.layer1[0].weight.shape[0])\n",
    "CIs[2] = get_ci(X, layer=torch.nn.Sequential(*(list(model.layer1)+list(model.layer2)))[0:4], sfm_filter=model.layer1[2].filter, n_filters=model.layer2[0].weight.shape[0])\n",
    "CIs[3] = get_ci(X, layer=torch.nn.Sequential(*(list(model.layer1)+list(model.layer2)+list(model.layer3)))[0:7], sfm_filter=tuple(np.multiply(model.layer1[2].filter, model.layer2[2].filter)), n_filters=model.layer3[0].weight.shape[0])\n",
    "CIs[4] = get_ci(X, layer=torch.nn.Sequential(*(list(model.layer1)+list(model.layer2)+list(model.layer3)+list(model.layer4)))[0:10], sfm_filter=tuple(np.multiply(np.multiply(model.layer1[2].filter, model.layer2[2].filter), model.layer3[2].filter)), n_filters=model.layer4[0].weight.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_channels == 1:\n",
    "    plot_map(FMs[1].permute(0, 2, 3, 1).reshape(int(len(model.layer1[0].weight)**0.5), int(len(model.layer1[0].weight)**0.5), *model.layer1[0].kernel_size, 1).detach().cpu().numpy())\n",
    "plot_map(FMs[2].permute(0, 2, 3, 1).reshape(int(len(model.layer2[0].weight)**0.5), int(len(model.layer2[0].weight)**0.5), *model.layer2[0].kernel_size, 1).detach().cpu().numpy())\n",
    "plot_map(FMs[3].permute(0, 2, 3, 1).reshape(int(len(model.layer3[0].weight)**0.5), int(len(model.layer3[0].weight)**0.5), *model.layer3[0].kernel_size, 1).detach().cpu().numpy())\n",
    "plot_map(FMs[4].permute(0, 2, 3, 1).reshape(int(len(model.layer4[0].weight)**0.5), int(len(model.layer4[0].weight)**0.5), *model.layer4[0].kernel_size, 1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(CIs[1].reshape(int(len(model.layer1[0].weight)**0.5), int(len(model.layer1[0].weight)**0.5), in_channels, *model.layer1[0].kernel_size).permute(0, 1, 3, 4, 2))\n",
    "plot_map(CIs[2].reshape(int(len(model.layer2[0].weight)**0.5), int(len(model.layer2[0].weight)**0.5), in_channels, *(np.array(model.layer1[2].filter) * model.layer1[0].kernel_size)).permute(0, 1, 3, 4, 2))\n",
    "plot_map(CIs[3].reshape(int(len(model.layer3[0].weight)**0.5), int(len(model.layer3[0].weight)**0.5), in_channels, *(np.multiply(model.layer1[2].filter, model.layer2[2].filter) * model.layer1[0].kernel_size)).permute(0, 1, 3, 4, 2))\n",
    "plot_map(CIs[4].reshape(int(len(model.layer4[0].weight)**0.5), int(len(model.layer4[0].weight)**0.5), in_channels, *(np.multiply(np.multiply(model.layer1[2].filter, model.layer2[2].filter), model.layer3[2].filter) * model.layer1[0].kernel_size)).permute(0, 1, 3, 4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot explainable process of a single image for MNIST and Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in range(0, out_channels):\n",
    "    all_target_idx = np.where(y == target)[0]\n",
    "    to_show = 1\n",
    "    save = f\"mnist-16-{target}\"\n",
    "    save = None\n",
    "\n",
    "    for i in range(len(all_target_idx)):\n",
    "        if to_show == 0: break\n",
    "        input_x = X[all_target_idx[i]][None, :, :, :]\n",
    "        pred = model(input_x)\n",
    "        if(pred.argmax() == target): continue\n",
    "        to_show -= 1\n",
    "        np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "        print(f\"target: {target}, pred: {pred.argmax()}\\nProb.: {pred.detach().numpy()}\")\n",
    "        infer_data(input_x, model, [CIs[1].squeeze(), CIs[2].squeeze(), CIs[3].squeeze(), CIs[4].squeeze()], save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot explainable process of a single image for Malaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 1 # 0: infected, 1: uninfected\n",
    "count = 2\n",
    "for idx in range(100):\n",
    "    if count == 0:\n",
    "        break\n",
    "    pred_p = model(X[y==target][idx:idx+1])\n",
    "    pred = pred_p.argmax()\n",
    "    if pred == target: # if equal to target, that is successfully classified, if not, that is misclassified\n",
    "        continue\n",
    "    np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "    print(f\"target: {target}, pred: {pred.argmax()}\\nProb.: {pred_p.detach().numpy()}\")\n",
    "    count -= 1\n",
    "    plt.imshow(X[y==target][idx].permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plot_map(RMs[1][y==target][idx].reshape(6, 6, 15, 15, 1).detach().numpy())\n",
    "    plot_map(FMs[1]['gray'][torch.topk(RMs[1][y==target][idx][:, 0:206], k=1, dim=1)[1]].reshape(6, 6, 5, 5, 1).detach().numpy())\n",
    "    plot_map(FMs[1]['rgb'][torch.topk(RMs[1][y==target][idx][:, 206:], k=1, dim=1)[1]].reshape(6, 6, 3, 5, 5).permute(0, 1, 3, 4, 2).detach().numpy())\n",
    "    plot_map(RMs[2][y==target][idx].reshape(3, 3, 25, 25, 1).detach().numpy())\n",
    "    plot_map(CIs[2][torch.topk(RMs[2][y==target][idx], k=1, dim=1)[1]].reshape(*model.layer2[2].shape, X.shape[1], 10, 10).permute(0, 1, 3, 4, 2))\n",
    "    plot_map(RMs[3][y==target][idx].reshape(3, 1, 30, 30, 1).detach().numpy())\n",
    "    plot_map(CIs[3][torch.topk(RMs[3][y==target][idx], k=1, dim=1)[1]].reshape(*model.layer3[2].shape, X.shape[1], 10, 30).permute(0, 1, 3, 4, 2))\n",
    "    plt.imshow(RMs[4][y==target][idx].reshape(45, 45, 1).detach().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plot_map(CIs[4][torch.topk(RMs[4][y==target][idx], k=20, dim=1)[1]].mean(1).reshape(1, 1, X.shape[1], 30, 30).permute(0, 1, 3, 4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation method for Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_neuron = 1\n",
    "k = 10\n",
    "rm_idx = 0\n",
    "n_FM4 = kernels[3][0]*kernels[3][1]\n",
    "target_RM = RMs[4][y==target_neuron]\n",
    "\n",
    "plt.imshow(target_RM[rm_idx].reshape(*kernels[3]).detach().numpy())\n",
    "plt.show()\n",
    "plt.imshow(model.fc1.weight[target_neuron].reshape(*kernels[3]).detach().numpy())\n",
    "plt.show()\n",
    "plt.imshow((target_RM[rm_idx].reshape(-1, n_FM4) * model.fc1.weight[target_neuron]).reshape(*kernels[3]).detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "wx_topk_list = {}\n",
    "x_topk_list = {}\n",
    "for i in tqdm(range(len(target_RM))):\n",
    "    wx = target_RM[i].reshape(-1, n_FM4) * model.fc1.weight[target_neuron]\n",
    "    wx_topk = torch.topk(wx, k)[1][0]\n",
    "    x_topk = torch.topk(target_RM[i].reshape(-1, n_FM4), k)[1][0]\n",
    "    for j in range(k):\n",
    "        wx_key = int(wx_topk[j]) \n",
    "        if wx_key in wx_topk_list:\n",
    "            wx_topk_list[wx_key] += 1\n",
    "        else:\n",
    "            wx_topk_list[wx_key] = 1\n",
    "            \n",
    "        x_key = int(x_topk[j]) \n",
    "        if x_key in x_topk_list:\n",
    "            x_topk_list[x_key] += 1\n",
    "        else:\n",
    "            x_topk_list[x_key] = 1\n",
    "            \n",
    "wx_topk_list = dict(sorted(wx_topk_list.items(), key=lambda item: item[1]))\n",
    "x_topk_list = dict(sorted(x_topk_list.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx_topk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_topk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Values and indices from top k of RM4:\\n{torch.topk(RMs[4].reshape(-1, 1, 1, *kernels[3])[y==target_neuron][0][0][0].reshape(n_FM4), k)}\\n\")\n",
    "print(f\"Values and indices from top k of FC layer:\\n{torch.topk(model.fc1.weight[target_neuron], k)}\\n\")\n",
    "print(f\"Values and indices from top k of RM4*weight:\\n{torch.topk((RMs[4].reshape(-1, 1, 1, *kernels[3])[y==target_neuron][0][0][0].reshape(-1, n_FM4) * model.fc1.weight[target_neuron]), k)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traingle(x, m, w):\n",
    "    dist = torch.dist(x, m)\n",
    "    return torch.ones_like(dist) - torch.minimum(dist, w) / w\n",
    "\n",
    "def trapezoidal(x, m, w, b):\n",
    "    dist = torch.dist(x, m)\n",
    "    tri = (torch.ones_like(dist)  - torch.minimum(dist, w) / w )\n",
    "    return tri - torch.where((tri <= b), tri, torch.tensor(0.0))\n",
    "\n",
    "def gaussian(x, m, w):\n",
    "    dist = torch.dist(x, m)\n",
    "    return torch.exp(-(dist ** 2) / (2 * w ** 2))\n",
    "\n",
    "def cReLU(x, b):\n",
    "    return x * torch.ge(x, b).float()\n",
    "def ReLU(x):\n",
    "    return x * torch.ge(x, 0).float()\n",
    "\n",
    "    \n",
    "m = torch.tensor(0.0)\n",
    "w = torch.tensor(5)\n",
    "b = torch.tensor(0.4)\n",
    "\n",
    "x = torch.linspace(m - 2 * w, m + 2 * w, 1000)\n",
    "y0 = [gaussian(i, m, w) for i in x]\n",
    "y1 = [traingle(i, m, w) for i in x]\n",
    "y2 = [trapezoidal(i, m, w, b) for i in x]\n",
    "y3 = [gaussian(i, torch.tensor(0.0), torch.tensor(0.447)) for i in x]\n",
    "y4 = [gaussian(i, torch.tensor(0.0), torch.tensor(1.0)) for i in x]\n",
    "y5 = [gaussian(i, torch.tensor(0.0), torch.tensor(2.23)) for i in x]\n",
    "y6 = [gaussian(i, torch.tensor(-2.0), torch.tensor(0.707)) for i in x]\n",
    "x1 = torch.linspace(0.4, m + 2 * w, 1000)\n",
    "cr1 = [cReLU(i, b) for i in x1]\n",
    "x2 = torch.linspace(m - 2 * w, 0.4-(1e-7), 1000)\n",
    "cr2 = [cReLU(i, b) for i in x2]\n",
    "relu = [ReLU(i) for i in x]\n",
    "\n",
    "plt.plot(x, y0)\n",
    "plt.title(f\"m = {m.item()}, σ = {w.item()}\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ϕ(x)')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, y1)\n",
    "plt.title(f\"m = {m.item()}, w = {w.item()}\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ϕ(x)')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, y2)\n",
    "plt.title(f\"m = {m.item()}, w = {w.item()}, b = {0.4}\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ϕ(x)')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, y3, label='m =  0, σ = 0.5')\n",
    "plt.plot(x, y4, label='m =  0, σ = 1.0', color=\"red\")\n",
    "plt.plot(x, y5, label='m =  0, σ = 2.2')\n",
    "plt.plot(x, y6, label='m = -2, σ = 0.7')\n",
    "p1 = (-1, gaussian(torch.tensor(-1.0), torch.tensor(0.0), torch.tensor(1.0)))\n",
    "plt.plot(*p1, 'go') \n",
    "plt.annotate(f\"{p1[0], round(p1[1].item(), 1)}\", (p1[0]-0.1, round(p1[1].item(), 1)-0.1))\n",
    "p2 = (2, gaussian(torch.tensor(2.0), torch.tensor(0.0), torch.tensor(1.0)))\n",
    "plt.plot(*p2, 'go') \n",
    "plt.annotate(f\"{p2[0], round(p2[1].item(), 1)}\", (p2[0]+0.1, round(p2[1].item(), 1)+0.1))\n",
    "\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ϕ(x)')\n",
    "plt.show()\n",
    "\n",
    "plt.plot([0, 0], [-10, 10], color=\"black\")\n",
    "plt.plot(x1, cr1, color=\"blue\")\n",
    "plt.plot(x2, cr2, color=\"blue\")\n",
    "plt.title(f\"c = {0.4}\")\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-0.1, 1])\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.2))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('c ReLU (x)')\n",
    "plt.show()\n",
    "\n",
    "plt.plot([0, 0], [-10, 10], color=\"black\")\n",
    "plt.plot(x, relu, color=\"blue\")\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-0.1, 1])\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.2))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ReLU (x)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "w = np.array([1, -2])  \n",
    "b = 0  \n",
    "\n",
    "num_points = 100\n",
    "x = np.random.uniform(-5, 5, (num_points, 2))  \n",
    "x = np.append(x, np.array([[10, 2]]), axis=0)\n",
    "x = np.append(x, np.array([[1, -2]]), axis=0)\n",
    "\n",
    "\n",
    "labels = np.sign(np.dot(x, w) + b)\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1], c=labels)\n",
    "plt.plot([-5, 10], [(-w[0] * (-5) - b) / w[1], (-w[0] * 10 - b) / w[1]], 'r')\n",
    "plt.annotate('(1, -2)', xy=(1, -2), xytext=(3, -1), arrowprops=dict(arrowstyle='->'))\n",
    "plt.annotate('(10, 2)', xy=(10, 2), xytext=(9, 0), arrowprops=dict(arrowstyle='->'))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "hyperplane_x = 0  \n",
    "hyperplane_y = (-w[0] * hyperplane_x - b) / w[1]  \n",
    "\n",
    "plt.annotate('Decision Boundary', xy=(hyperplane_x, hyperplane_y), xytext=(1, 5), arrowprops=dict(arrowstyle='->'))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47b75fb8d8aa71c612710195ff4b16aa9497d5554f8641a297ce0b115b33ab61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
